{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Areal Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"logo.jpg\" width=150 ALIGN=\"left\" border=\"20\">\n",
    "<h1> Starting Kit for preprocessed data</h1>\n",
    "<br>This code was tested with <br>\n",
    "Python 3.6.7 <br>\n",
    "Created by Areal Team <br><br>\n",
    "ALL INFORMATION, SOFTWARE, DOCUMENTATION, AND DATA ARE PROVIDED \"AS-IS\". The CDS, CHALEARN, AND/OR OTHER ORGANIZERS OR CODE AUTHORS DISCLAIM ANY EXPRESSED OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR ANY PARTICULAR PURPOSE, AND THE WARRANTY OF NON-INFRIGEMENT OF ANY THIRD PARTY'S INTELLECTUAL PROPERTY RIGHTS. IN NO EVENT SHALL AUTHORS AND ORGANIZERS BE LIABLE FOR ANY SPECIAL, \n",
    "INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF SOFTWARE, DOCUMENTS, MATERIALS, PUBLICATIONS, OR INFORMATION MADE AVAILABLE FOR THE CHALLENGE. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h2>Introduction </h2>\n",
    "     <br>\n",
    "Aerial imagery has been a primary source of geographic data for quite a long time. With technology progress, aerial imagery became really practical for remote sensing : the science of obtaining information about an object, area or phenomenon.\n",
    "Nowadays, there are many uses of image recognition spanning from robotics/drone vision to autonomous driving vehicules or face detection.\n",
    "<br>\n",
    "In this challenge, we will use pre-processed data, coming from landscape images. The goal is to learn to differentiate common and uncommon landscapes such as a beach, a lake or a meadow.\n",
    "    Data comes from part of the data set (NWPU-RESISC45) originally used in <a href=\"https://arxiv.org/pdf/1703.00121.pdf?fbclid=IwAR16qo-EX_Z05ZpxvWG8F-oBU0SlnY-3BPCWBVVOGPyJcVy7BBqCKjnsvJo\">Remote Sensing Image Scene Classification</a>. This data set contains 45 categories while we only kept 13 out of them.\n",
    "\n",
    "References and credits: \n",
    "Yuliya Tarabalka, Guillaume Charpiat, Nicolas Girard for the data sets presentation.<br>\n",
    "Gong Cheng, Junwei Han, and Xiaoqiang Lu, for the original article on the chosen data set.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements \n",
    "\n",
    "Our code uses multiple libraries, so the next cell will install python's required dependencies (probably only possible on your personal computers). In case you don't want to, or are running in the competition's docker, you can comment it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"sample_code_submission/\"\n",
    "result_dir = 'sample_result_submission/' \n",
    "problem_dir = 'ingestion_program/'  \n",
    "score_dir = 'scoring_program/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path; path.append(model_dir); path.append(problem_dir); path.append(score_dir);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <h1> Step 1: Exploratory data analysis </h1>\n",
    "<p>\n",
    "We provide sample_data with the starting kit, but to prepare your submission, you must fetch the public_data from the challenge website and point to it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"CNN.png\" width=800 align=\"center\" border=\"20\">\n",
    "We used a special Convolutional Neural Network (CNN) already trained to recognize images in order to create the new data. To create it, we kept the form of the data at three-fourth in the CNN. <br>\n",
    "This new form is highly similar to weights we can see in a classic neural network.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'public_data'\n",
    "data_name = 'Areal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading public_data/Areal_train from AutoML format\n"
     ]
    }
   ],
   "source": [
    "from ingestion_program.data_io import read_as_df\n",
    "data = read_as_df(data_dir  + '/' + data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data.iloc[:, -1:])\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of values\n",
    "\n",
    "Most values are in the range (0, 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(30,15))\n",
    "# Plot values of first 10 features\n",
    "data_plot=data.iloc[:,:10]\n",
    "data_plot.boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation as images\n",
    "\n",
    "Although any human won't be able to make sense of those images, it is by far simpler and faster for computers to correctly recognize those \"images\" and assign them their correct classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "num_toshow = 6\n",
    "fig, _axs = plt.subplots(nrows=2, ncols=3, figsize=(10,10))\n",
    "fig.subplots_adjust(hspace=0.3)\n",
    "axs = _axs.flatten()\n",
    "\n",
    "for i in range(num_toshow):\n",
    "    img = data.iloc[i].values[:-1].reshape(32, 32)\n",
    "    label = data.values[i][-1:]\n",
    "    axs[i].set_title('Example of {}'.format(label))\n",
    "    axs[i].imshow(img.astype(float))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Building a predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use DataManager to separate data for train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_manager import DataManager\n",
    "D = DataManager(data_name, data_dir)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data and labels by calling D.data (DataManager.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = D.data['X_train']\n",
    "Y_train = D.data['Y_train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is a simpler version of the decision tree algorithm of sklearn.\n",
    "\n",
    "You can only change the parameter max_depth which has a default value of 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import UltimateClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = UltimateClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model\n",
    "\n",
    "Data as first argument, Labels as second, with .reshape(-1) to make sure that the array containing labels is flat and don't have multiple dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.fit(X_train, Y_train.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_train = M.predict(D.data['X_train'])\n",
    "Y_hat_valid = M.predict(D.data['X_valid'])\n",
    "Y_hat_test = M.predict(D.data['X_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#M.save(trained_model_name)            \n",
    "\n",
    "\"\"\"\n",
    "import seaborn as sns; sns.set()\n",
    "sns.pairplot(data, hue=\"target\"), \n",
    "corr_mat = data.corr(method='spearman')\n",
    "sns.heatmap(corr_mat, annot=True, center=0)\n",
    "\"\"\"\n",
    "\n",
    "result_name = result_dir + data_name\n",
    "from data_io import write\n",
    "from data_io import mkdir\n",
    "mkdir(result_dir)\n",
    "\n",
    "write(result_name + '_train.predict', Y_hat_train)\n",
    "write(result_name + '_valid.predict', Y_hat_valid)\n",
    "write(result_name + '_test.predict', Y_hat_test)\n",
    "!ls $result_name*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libscores import get_metric\n",
    "metric_name, scoring_function = get_metric()\n",
    "print('Using scoring metric:', metric_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print('Ideal score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_train), \"\\n\")\n",
    "\n",
    "print(\"Scores with BaselineModel\")\n",
    "print('Training score for the', metric_name, 'metric = %5.4f' % scoring_function(Y_train, Y_hat_train))\n",
    "if len(D.data['Y_valid'] > 0) and len(D.data['Y_test'] > 0):\n",
    "    print('Validation score for the', metric_name, 'metric = %5.4f' % scoring_function(D.data['Y_valid'], Y_hat_valid))\n",
    "    print('Test score for the', metric_name, 'metric = %5.4f' % scoring_function(D.data['Y_test'], Y_hat_test))\n",
    "\"\"\"\n",
    "from model import compute_accuracy\n",
    "rep = compute_accuracy(M, D, \"Ultimate Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the provided model is one that heavily overfits so you shouldn't look too much at the training score.\n",
    "\n",
    "Using cross-validation (see a bit below) will give more significant results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix\n",
    "\n",
    "Doesn't have much value on train with a 100% accuracy, but it can be good to look at if you change your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(Y_train, Y_hat_train)\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = \"\"\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    #print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation\n",
    "\n",
    "Because validation and test labels should first not be available, we do cross validation to see our models quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(M, X_train, Y_train.ravel(), cv=5, scoring=make_scorer(scoring_function))\n",
    "print('\\nCV score (95 perc. CI): %0.2f (+/- %0.2f)' % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "## Example\n",
    "\n",
    "Example needs to have python3 installed\n",
    "\n",
    "Test to see whether submission with ingestion program is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!python3 $problem_dir/ingestion.py $data_dir $result_dir $problem_dir $model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test scoring program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_output_dir = 'scoring_output'\n",
    "!python3 $score_dir/score.py $data_dir $result_dir $scoring_output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "from data_io import zipdir\n",
    "the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "sample_code_submission = './sample_code_submission_prep_' + the_date + '.zip'\n",
    "sample_result_submission = './sample_result_submission_prep_' + the_date + '.zip'\n",
    "zipdir(sample_code_submission, model_dir)\n",
    "zipdir(sample_result_submission, result_dir)\n",
    "print(\"Submit one of these files:\\n\" + sample_code_submission + \"\\n\" + sample_result_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
